{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as tr\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "# from torchvision.datasets import CIFAR10\n",
    "# from torch.utils.data import DataLoader\n",
    "# from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from train import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a dataloader that returns a anchor, positive and negative when iterating over it. This can then be passed into the encoding network and then you can calcualte the loss. This ideally would have a triplet on or triplet off functionality. So, when triplet is off ___get_item___ returns 1 image and corresponding label to be used with classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TripletsMNIST(Dataset):\n",
    "    def __init__(self, root=\"./data\", train=True, transform=None, triplet_training):\n",
    "        transform = self.get_default_transform()\n",
    "        self.mnist_dataset = MNIST(root=root, train=train, transform=transform, download=False)\n",
    "        self.targets = self.mnist_dataset.targets\n",
    "        self.triplets = self._generate_triplets()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        anchor, positive, negative = self.triplets[index]\n",
    "        anchor_img, _ = self.mnist_dataset[anchor]\n",
    "        positive_img, _ = self.mnist_dataset[int(positive)]\n",
    "        negative_img, _ = self.mnist_dataset[int(negative)]\n",
    "        return anchor_img, positive_img, negative_img\n",
    "    \n",
    "    def get_default_transform(self):\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Grayscale(\n",
    "                    num_output_channels=3\n",
    "                ),  # Convert to 3 channel grayscale\n",
    "                transforms.Resize((32, 32)),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        return transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def _generate_triplets(self, debug=True):\n",
    "        triplets = []\n",
    "        for i in range(len(self.mnist_dataset)):\n",
    "            anchor_img, anchor_label = self.mnist_dataset[i]\n",
    "            positive_indices = torch.where(self.targets == anchor_label)[0]\n",
    "            negative_indices = torch.where(self.targets != anchor_label)[0]\n",
    "\n",
    "            if len(positive_indices) < 2 or len(negative_indices) < 1:\n",
    "                continue\n",
    "\n",
    "            positive_idx = positive_indices[torch.randint(high=len(positive_indices), size=(1,))]\n",
    "            negative_idx = negative_indices[torch.randint(high=len(negative_indices), size=(1,))]\n",
    "\n",
    "            triplets.append((i, positive_idx, negative_idx))\n",
    "\n",
    "            if debug and i > 100:\n",
    "                break\n",
    "        return triplets\n",
    "    \n",
    "def triplet_collate(batch):\n",
    "    # concatenate anchor, positive, and negative tensors\n",
    "    anchor, positive, negative = zip(*batch)\n",
    "    anchor = torch.stack(anchor, dim=0)\n",
    "    positive = torch.stack(positive, dim=0)\n",
    "    negative = torch.stack(negative, dim=0)\n",
    "\n",
    "    # return triplet tensor\n",
    "    return torch.stack((anchor, positive, negative), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TripletsMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=10, shuffle=True, collate_fn=triplet_collate\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n",
      "torch.Size([10, 3, 32, 32])\n",
      "torch.Size([10, 3, 32, 32])\n",
      "torch.Size([10, 3, 32, 32])\n",
      "torch.Size([10, 3, 32, 32])\n",
      "torch.Size([10, 3, 32, 32])\n",
      "torch.Size([10, 3, 32, 32])\n",
      "torch.Size([10, 3, 32, 32])\n",
      "torch.Size([10, 3, 32, 32])\n",
      "torch.Size([10, 3, 32, 32])\n",
      "torch.Size([2, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for i,(a,p,n) in enumerate(train_loader):\n",
    "    # print(f\"i: {i}, n: {n.shape}, a: {a.shape}\")\n",
    "    print(a.shape)\n",
    "    if i > 10: \n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simclr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
